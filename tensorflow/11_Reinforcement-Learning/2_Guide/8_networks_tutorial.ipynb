{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Pi_B2cvdBiW"
   },
   "source": [
    "##### Copyright 2021 The TF-Agents Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2021-08-25T20:19:07.453077Z",
     "iopub.status.busy": "2021-08-25T20:19:07.452315Z",
     "iopub.status.idle": "2021-08-25T20:19:07.455270Z",
     "shell.execute_reply": "2021-08-25T20:19:07.454743Z"
    },
    "id": "nQnmcm0oI1Q-"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GiI8CZYWcJ5n"
   },
   "source": [
    "# 네트워크\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td><a target=\"_blank\" href=\"https://www.tensorflow.org/agents/tutorials/8_networks_tutorial\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\">TensorFlow.org에서 보기</a></td>\n",
    "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/ko/agents/tutorials/8_networks_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\">Google Colab에서 실행하기</a></td>\n",
    "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/ko/agents/tutorials/8_networks_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\">GitHub에서 소스 보기</a></td>\n",
    "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/ko/agents/tutorials/8_networks_tutorial.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\">노트북 다운로드하기</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31uij8nIo5bG"
   },
   "source": [
    "## 소개\n",
    "\n",
    "이 colab에서는 에이전트에 대한 사용자 정의 네트워크를 정의하는 방법을 다룹니다. 네트워크는 에이전트를 통해 훈련되는 모델을 정의하는 데 도움이 됩니다. TF-Agents에는 에이전트에 유용한 여러 가지 유형의 네트워크가 있습니다.\n",
    "\n",
    "**주요 네트워크**\n",
    "\n",
    "- **QNetwork**: 불연속 행동이 있는 환경에 대한 Qlearning에서 사용되는 이 네트워크는 관찰 값을 가능한 각 행동에 대한 추정 값에 매핑합니다.\n",
    "- **CriticNetworks**: 문헌에서 `ValueNetworks`라고도 하며 일부 상태를 예상되는 정책 반환의 추정에 매핑하는 일부 Value 함수 버전을 추정하는 방법을 학습합니다. 이 네트워크는 에이전트의 현재 상태가 얼마나 좋은지 추정합니다.\n",
    "- **ActorNetworks**: 관찰 값에서 행동으로의 매핑을 학습합니다. 이러한 네트워크는 일반적으로 정책에서 행동을 생성하는 데 사용됩니다.\n",
    "- **ActorDistributionNetworks**: `ActorNetworks`와 유사하지만 정책이 행동을 생성하기 위해 샘플링할 수 있는 분포를 생성합니다.\n",
    "\n",
    "**도우미 네트워크**\n",
    "\n",
    "- **EncodingNetwork** : 사용자는 네트워크의 입력에 적용 할 전처리 레이어의 매핑을 쉽게 정의 할 수 있습니다.\n",
    "- **DynamicUnrollLayer** : 시간 순서에 따라 적용되는 에피소드 경계에서 네트워크 상태를 자동으로 재설정합니다.\n",
    "- **ProjectionNetwork**: `CategoricalProjectionNetwork` 또는 `NormalProjectionNetwork`와 같은 네트워크는 입력을 받아 범주형 또는 정규 분포를 생성하는 데 필요한 매개변수를 생성합니다.\n",
    "\n",
    "TF-Agents의 모든 예에는 사전 구성된 네트워크가 함께 제공됩니다. 그러나 이러한 네트워크는 복잡한 관찰 값을 처리하도록 설정되지 않습니다.\n",
    "\n",
    "둘 이상의 관측 값/행동을 노출하는 환경에 있으면서 네트워크를 사용자 정의해야 하는 경우 이 튜토리얼을 제대로 찾았습니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wmk1GBT9cPqC"
   },
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uhGeL1Kpc3Pw"
   },
   "source": [
    "tf-agent를 아직 설치하지 않은 경우 다음을 실행하십시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:19:07.462658Z",
     "iopub.status.busy": "2021-08-25T20:19:07.462091Z",
     "iopub.status.idle": "2021-08-25T20:19:12.016659Z",
     "shell.execute_reply": "2021-08-25T20:19:12.017133Z"
    },
    "id": "xsLTHlVdiZP3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-agents\r\n",
      "  Using cached tf_agents-0.9.0-py3-none-any.whl (1.3 MB)\r\n",
      "Requirement already satisfied: six>=1.10.0 in /tmpfs/src/tf_docs_env/lib/python3.7/site-packages (from tf-agents) (1.15.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /tmpfs/src/tf_docs_env/lib/python3.7/site-packages (from tf-agents) (1.12.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /tmpfs/src/tf_docs_env/lib/python3.7/site-packages (from tf-agents) (3.7.4.3)\r\n",
      "Requirement already satisfied: absl-py>=0.6.1 in /home/kbuilder/.local/lib/python3.7/site-packages (from tf-agents) (0.12.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cloudpickle>=1.3\r\n",
      "  Using cached cloudpickle-1.6.0-py3-none-any.whl (23 kB)\r\n",
      "Requirement already satisfied: protobuf>=3.11.3 in /home/kbuilder/.local/lib/python3.7/site-packages (from tf-agents) (3.17.3)\r\n",
      "Collecting tensorflow-probability>=0.13.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached tensorflow_probability-0.13.0-py2.py3-none-any.whl (5.4 MB)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /tmpfs/src/tf_docs_env/lib/python3.7/site-packages (from tf-agents) (1.19.5)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym>=0.17.0\r\n",
      "  Using cached gym-0.19.0-py3-none-any.whl\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gin-config>=0.4.0\r\n",
      "  Using cached gin_config-0.4.0-py2.py3-none-any.whl (46 kB)\r\n",
      "Requirement already satisfied: gast>=0.3.2 in /tmpfs/src/tf_docs_env/lib/python3.7/site-packages (from tensorflow-probability>=0.13.0->tf-agents) (0.4.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: decorator in /home/kbuilder/.local/lib/python3.7/site-packages (from tensorflow-probability>=0.13.0->tf-agents) (5.0.9)\r\n",
      "Collecting dm-tree\r\n",
      "  Using cached dm_tree-0.1.6-cp37-cp37m-manylinux_2_24_x86_64.whl (93 kB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: dm-tree, cloudpickle, tensorflow-probability, gym, gin-config, tf-agents\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed cloudpickle-1.6.0 dm-tree-0.1.6 gin-config-0.4.0 gym-0.19.0 tensorflow-probability-0.13.0 tf-agents-0.9.0\r\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 21.2.4 is available.\r\n",
      "You should consider upgrading via the '/tmpfs/src/tf_docs_env/bin/python -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tf-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:19:12.025089Z",
     "iopub.status.busy": "2021-08-25T20:19:12.024461Z",
     "iopub.status.idle": "2021-08-25T20:19:13.965835Z",
     "shell.execute_reply": "2021-08-25T20:19:13.965281Z"
    },
    "id": "sdvop99JlYSM"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import abc\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tf_agents.environments import random_py_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import encoding_network\n",
    "from tf_agents.networks import network\n",
    "from tf_agents.networks import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.utils import common as common_utils\n",
    "from tf_agents.utils import nest_utils\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ums84-YP_21F"
   },
   "source": [
    "## 네트워크 정의하기\n",
    "\n",
    "### 네트워크 API\n",
    "\n",
    "TF-Agents에서는 Keras [Networks](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/network.py)를 하위 클래스화합니다. 그러면 다음을 수행할 수 있습니다.\n",
    "\n",
    "- 대상 네트워크를 만들 때 필요한 복사 작업을 단순화합니다.\n",
    "- `network.variables()`를 호출할 때 자동 변수 생성을 수행합니다.\n",
    "- 네트워크 input_spec을 기반으로 입력을 검증합니다.\n",
    "\n",
    "EncodingNetwork는 대부분 선택적인 다음과 같은 레이어로 구성됩니다.\n",
    "\n",
    "네트워크 인코딩의 특별한 점은 입력 전처리가 적용된다는 것입니다. 입력 전처리는 `preprocessing_layers` 및 `preprocessing_combiner` 레이어를 통해 가능합니다. 이러한 레이어 각각은 중첩 구조로 지정할 수 있습니다. `preprocessing_layers` 중첩이 `input_tensor_spec` 보다 얕으면 레이어에 하위 중첩이 생깁니다. 예를 들어, 다음과 같다면\n",
    "\n",
    "- 전처리 레이어\n",
    "- 전처리 결합기\n",
    "- 전환\n",
    "- 반음 낮추다\n",
    "- 밀집한\n",
    "\n",
    "전처리가 다음을 호출합니다.\n",
    "\n",
    "```\n",
    "input_tensor_spec = ([TensorSpec(3)] * 2, [TensorSpec(3)] * 5) preprocessing_layers = (Layer1(), Layer2())\n",
    "```\n",
    "\n",
    "그러나 다음과 같다면\n",
    "\n",
    "```\n",
    "preprocessed = [preprocessing_layers[0](observations[0]),                 preprocessing_layers[1](obsrevations[1])]\n",
    "```\n",
    "\n",
    "전처리는 다음을 호출합니다.\n",
    "\n",
    "```\n",
    "preprocessing_layers = ([Layer1() for _ in range(2)],                         [Layer2() for _ in range(5)])\n",
    "```\n",
    "\n",
    "전처리는 다음을 호출합니다.\n",
    "\n",
    "```python\n",
    "preprocessed = [   layer(obs) for layer, obs in zip(flatten(preprocessing_layers),                                     flatten(observations)) ]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RP3H1bw0ykro"
   },
   "source": [
    "### 사용자 정의 네트워크\n",
    "\n",
    "자체 네트워크를 만들려면 `__init__` 및 `call` 메서드만 재정의하면 됩니다. `EncodingNetworks`에 대해 배운 내용을 이용해 사용자 정의 네트워크를 만들어 이미지와 벡터를 포함한 관찰 값을 취하는 ActorNetwork를 만들어 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:19:13.976678Z",
     "iopub.status.busy": "2021-08-25T20:19:13.975906Z",
     "iopub.status.idle": "2021-08-25T20:19:13.977770Z",
     "shell.execute_reply": "2021-08-25T20:19:13.978144Z"
    },
    "id": "Zp0TjAJhYo4s"
   },
   "outputs": [],
   "source": [
    "class ActorNetwork(network.Network):\n",
    "\n",
    "  def __init__(self,\n",
    "               observation_spec,\n",
    "               action_spec,\n",
    "               preprocessing_layers=None,\n",
    "               preprocessing_combiner=None,\n",
    "               conv_layer_params=None,\n",
    "               fc_layer_params=(75, 40),\n",
    "               dropout_layer_params=None,\n",
    "               activation_fn=tf.keras.activations.relu,\n",
    "               enable_last_layer_zero_initializer=False,\n",
    "               name='ActorNetwork'):\n",
    "    super(ActorNetwork, self).__init__(\n",
    "        input_tensor_spec=observation_spec, state_spec=(), name=name)\n",
    "\n",
    "    # For simplicity we will only support a single action float output.\n",
    "    self._action_spec = action_spec\n",
    "    flat_action_spec = tf.nest.flatten(action_spec)\n",
    "    if len(flat_action_spec) > 1:\n",
    "      raise ValueError('Only a single action is supported by this network')\n",
    "    self._single_action_spec = flat_action_spec[0]\n",
    "    if self._single_action_spec.dtype not in [tf.float32, tf.float64]:\n",
    "      raise ValueError('Only float actions are supported by this network.')\n",
    "\n",
    "    kernel_initializer = tf.keras.initializers.VarianceScaling(\n",
    "        scale=1. / 3., mode='fan_in', distribution='uniform')\n",
    "    self._encoder = encoding_network.EncodingNetwork(\n",
    "        observation_spec,\n",
    "        preprocessing_layers=preprocessing_layers,\n",
    "        preprocessing_combiner=preprocessing_combiner,\n",
    "        conv_layer_params=conv_layer_params,\n",
    "        fc_layer_params=fc_layer_params,\n",
    "        dropout_layer_params=dropout_layer_params,\n",
    "        activation_fn=activation_fn,\n",
    "        kernel_initializer=kernel_initializer,\n",
    "        batch_squash=False)\n",
    "\n",
    "    initializer = tf.keras.initializers.RandomUniform(\n",
    "        minval=-0.003, maxval=0.003)\n",
    "\n",
    "    self._action_projection_layer = tf.keras.layers.Dense(\n",
    "        flat_action_spec[0].shape.num_elements(),\n",
    "        activation=tf.keras.activations.tanh,\n",
    "        kernel_initializer=initializer,\n",
    "        name='action')\n",
    "\n",
    "  def call(self, observations, step_type=(), network_state=()):\n",
    "    outer_rank = nest_utils.get_outer_rank(observations, self.input_tensor_spec)\n",
    "    # We use batch_squash here in case the observations have a time sequence\n",
    "    # compoment.\n",
    "    batch_squash = utils.BatchSquash(outer_rank)\n",
    "    observations = tf.nest.map_structure(batch_squash.flatten, observations)\n",
    "\n",
    "    state, network_state = self._encoder(\n",
    "        observations, step_type=step_type, network_state=network_state)\n",
    "    actions = self._action_projection_layer(state)\n",
    "    actions = common_utils.scale_to_spec(actions, self._single_action_spec)\n",
    "    actions = batch_squash.unflatten(actions)\n",
    "    return tf.nest.pack_sequence_as(self._action_spec, [actions]), network_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fm-MbMMLYiZj"
   },
   "source": [
    "`RandomPyEnvironment`를 생성하여 구조화된 관찰 값을 생성하고 구현을 검증해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:19:13.985785Z",
     "iopub.status.busy": "2021-08-25T20:19:13.985100Z",
     "iopub.status.idle": "2021-08-25T20:19:13.988547Z",
     "shell.execute_reply": "2021-08-25T20:19:13.988134Z"
    },
    "id": "E2XoNuuD66s5"
   },
   "outputs": [],
   "source": [
    "action_spec = array_spec.BoundedArraySpec((3,), np.float32, minimum=0, maximum=10)\n",
    "observation_spec =  {\n",
    "    'image': array_spec.BoundedArraySpec((16, 16, 3), np.float32, minimum=0,\n",
    "                                        maximum=255),\n",
    "    'vector': array_spec.BoundedArraySpec((5,), np.float32, minimum=-100,\n",
    "                                          maximum=100)}\n",
    "\n",
    "random_env = random_py_environment.RandomPyEnvironment(observation_spec, action_spec=action_spec)\n",
    "\n",
    "# Convert the environment to a TFEnv to generate tensors.\n",
    "tf_env = tf_py_environment.TFPyEnvironment(random_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LM3uDTD7TNVx"
   },
   "source": [
    "관찰 값이 사전이 되도록 정의했으므로 관찰 값을 처리하기 위한 전처리 레이어를 만들어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:19:13.993268Z",
     "iopub.status.busy": "2021-08-25T20:19:13.992616Z",
     "iopub.status.idle": "2021-08-25T20:19:15.557551Z",
     "shell.execute_reply": "2021-08-25T20:19:15.557005Z"
    },
    "id": "r9U6JVevTAJw"
   },
   "outputs": [],
   "source": [
    "preprocessing_layers = {\n",
    "    'image': tf.keras.models.Sequential([tf.keras.layers.Conv2D(8, 4),\n",
    "                                        tf.keras.layers.Flatten()]),\n",
    "    'vector': tf.keras.layers.Dense(5)\n",
    "    }\n",
    "preprocessing_combiner = tf.keras.layers.Concatenate(axis=-1)\n",
    "actor = ActorNetwork(tf_env.observation_spec(), \n",
    "                     tf_env.action_spec(),\n",
    "                     preprocessing_layers=preprocessing_layers,\n",
    "                     preprocessing_combiner=preprocessing_combiner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mM9qedlwc41U"
   },
   "source": [
    "이제 actor 네트워크가 생겼으므로 환경에서 관찰 값을 처리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-25T20:19:15.568469Z",
     "iopub.status.busy": "2021-08-25T20:19:15.566678Z",
     "iopub.status.idle": "2021-08-25T20:19:16.933578Z",
     "shell.execute_reply": "2021-08-25T20:19:16.934008Z"
    },
    "id": "JOkkeu7vXoei"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[4.866429, 5.182047, 5.05543 ]], dtype=float32)>,\n",
       " ())"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_step = tf_env.reset()\n",
    "actor(time_step.observation, time_step.step_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ALGxaQLWc9GI"
   },
   "source": [
    "이 같은 전략을 사용하여 에이전트가 사용하는 기본 네트워크를 사용자 정의 할 수 있습니다. 전처리를 정의하고 나머지 네트워크에 연결할 수 있습니다. 사용자 정의를 정의 할 때 네트워크의 출력 계층 정의가 일치하는지 확인하십시오."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "8_networks_tutorial.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
