{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(range(1,101)) # 1~100\n",
    "y = np.array(range(1,101))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=66, test_size=0.4)\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, random_state=66, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "20\n",
      "20\n",
      "60\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train))\n",
    "print(len(x_test))\n",
    "print(len(x_val))\n",
    "\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 0s 6ms/step - loss: 1567.9962 - mse: 1567.9962 - val_loss: 119602.2969 - val_mse: 119602.2969\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 840.4765 - mse: 840.4765 - val_loss: 430581.5000 - val_mse: 430581.5000\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 843.8874 - mse: 843.8874 - val_loss: 1995035.6250 - val_mse: 1995035.6250\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 834.0000 - mse: 834.0000 - val_loss: 12545787.0000 - val_mse: 12545787.0000\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 813.9796 - mse: 813.9796 - val_loss: 53773752.0000 - val_mse: 53773752.0000\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 888.5363 - mse: 888.5363 - val_loss: 363305792.0000 - val_mse: 363305792.0000\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 843.0312 - mse: 843.0312 - val_loss: 1671828992.0000 - val_mse: 1671828992.0000\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 859.7446 - mse: 859.7446 - val_loss: 8778105856.0000 - val_mse: 8778105856.0000\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 898.9665 - mse: 898.9665 - val_loss: 47173492736.0000 - val_mse: 47173492736.0000\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 848.2609 - mse: 848.2609 - val_loss: 164080713728.0000 - val_mse: 164080713728.0000\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 841.6368 - mse: 841.6368 - val_loss: 522046734336.0000 - val_mse: 522046734336.0000\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 790.4246 - mse: 790.4246 - val_loss: 902022103040.0000 - val_mse: 902022103040.0000\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 861.9824 - mse: 861.9824 - val_loss: 1438736187392.0000 - val_mse: 1438736187392.0000\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 883.5853 - mse: 883.5853 - val_loss: 3376708583424.0000 - val_mse: 3376708583424.0000\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 812.6028 - mse: 812.6028 - val_loss: 5168062005248.0000 - val_mse: 5168062005248.0000\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 831.9176 - mse: 831.9176 - val_loss: 4518955188224.0000 - val_mse: 4518955188224.0000\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 868.5856 - mse: 868.5856 - val_loss: 4922318782464.0000 - val_mse: 4922318782464.0000\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 935.1526 - mse: 935.1526 - val_loss: 7728606478336.0000 - val_mse: 7728606478336.0000\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 851.0093 - mse: 851.0093 - val_loss: 5987223732224.0000 - val_mse: 5987223732224.0000\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 799.5643 - mse: 799.5643 - val_loss: 4811822989312.0000 - val_mse: 4811822989312.0000\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 863.4166 - mse: 863.4166 - val_loss: 4392875458560.0000 - val_mse: 4392875458560.0000\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 899.0421 - mse: 899.0421 - val_loss: 3951287336960.0000 - val_mse: 3951287336960.0000\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 861.8594 - mse: 861.8594 - val_loss: 6064625942528.0000 - val_mse: 6064625942528.0000\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 756.0046 - mse: 756.0046 - val_loss: 3996768272384.0000 - val_mse: 3996768272384.0000\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 956.7167 - mse: 956.7167 - val_loss: 5161072721920.0000 - val_mse: 5161072721920.0000\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 816.6912 - mse: 816.6912 - val_loss: 6792193507328.0000 - val_mse: 6792193507328.0000\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 808.0908 - mse: 808.0908 - val_loss: 4730336051200.0000 - val_mse: 4730336051200.0000\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 871.1099 - mse: 871.1099 - val_loss: 5506550202368.0000 - val_mse: 5506550202368.0000\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 807.7819 - mse: 807.7819 - val_loss: 4242290245632.0000 - val_mse: 4242290245632.0000\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 956.6301 - mse: 956.6301 - val_loss: 4498716622848.0000 - val_mse: 4498716622848.0000\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 836.2114 - mse: 836.2114 - val_loss: 5515973754880.0000 - val_mse: 5515973754880.0000\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 845.9442 - mse: 845.9442 - val_loss: 5896745779200.0000 - val_mse: 5896745779200.0000\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 861.4028 - mse: 861.4028 - val_loss: 5925253414912.0000 - val_mse: 5925253414912.0000\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 919.9487 - mse: 919.9487 - val_loss: 5972963098624.0000 - val_mse: 5972963098624.0000\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 854.8489 - mse: 854.8489 - val_loss: 5197558972416.0000 - val_mse: 5197558972416.0000\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 823.6375 - mse: 823.6375 - val_loss: 4651448532992.0000 - val_mse: 4651448532992.0000\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 815.3283 - mse: 815.3283 - val_loss: 4542204215296.0000 - val_mse: 4542204215296.0000\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 826.4998 - mse: 826.4998 - val_loss: 5189400002560.0000 - val_mse: 5189400002560.0000\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 854.3585 - mse: 854.3585 - val_loss: 4532818935808.0000 - val_mse: 4532818935808.0000\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 819.8796 - mse: 819.8796 - val_loss: 6939661565952.0000 - val_mse: 6939661565952.0000\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 898.4948 - mse: 898.4948 - val_loss: 4704663764992.0000 - val_mse: 4704663764992.0000\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 856.9886 - mse: 856.9886 - val_loss: 4589601423360.0000 - val_mse: 4589601423360.0000\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 838.2559 - mse: 838.2559 - val_loss: 4620647661568.0000 - val_mse: 4620647661568.0000\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 870.2325 - mse: 870.2325 - val_loss: 4335922577408.0000 - val_mse: 4335922577408.0000\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 812.9363 - mse: 812.9363 - val_loss: 5606646743040.0000 - val_mse: 5606646743040.0000\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 828.7897 - mse: 828.7897 - val_loss: 5267665190912.0000 - val_mse: 5267665190912.0000\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 848.6816 - mse: 848.6816 - val_loss: 5455331983360.0000 - val_mse: 5455331983360.0000\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 841.5778 - mse: 841.5778 - val_loss: 4157313908736.0000 - val_mse: 4157313908736.0000\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 826.6593 - mse: 826.6593 - val_loss: 5002872487936.0000 - val_mse: 5002872487936.0000\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 849.2565 - mse: 849.2565 - val_loss: 4738610888704.0000 - val_mse: 4738610888704.0000\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 827.9580 - mse: 827.9580 - val_loss: 4587961974784.0000 - val_mse: 4587961974784.0000\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 834.8511 - mse: 834.8511 - val_loss: 4076782485504.0000 - val_mse: 4076782485504.0000\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 850.3295 - mse: 850.3295 - val_loss: 4475652669440.0000 - val_mse: 4475652669440.0000\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 814.6345 - mse: 814.6345 - val_loss: 3862536126464.0000 - val_mse: 3862536126464.0000\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 861.6873 - mse: 861.6873 - val_loss: 3649585545216.0000 - val_mse: 3649585545216.0000\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 851.8473 - mse: 851.8473 - val_loss: 5273342181376.0000 - val_mse: 5273342181376.0000\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 907.1591 - mse: 907.1591 - val_loss: 4926627381248.0000 - val_mse: 4926627381248.0000\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 839.3981 - mse: 839.3981 - val_loss: 5028591960064.0000 - val_mse: 5028591960064.0000\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 821.3903 - mse: 821.3903 - val_loss: 4621031440384.0000 - val_mse: 4621031440384.0000\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 795.6346 - mse: 795.6346 - val_loss: 3704075845632.0000 - val_mse: 3704075845632.0000\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 906.1765 - mse: 906.1765 - val_loss: 4689000136704.0000 - val_mse: 4689000136704.0000\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 847.6069 - mse: 847.6069 - val_loss: 5102294794240.0000 - val_mse: 5102294794240.0000\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 859.4882 - mse: 859.4882 - val_loss: 4404917305344.0000 - val_mse: 4404917305344.0000\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 813.9063 - mse: 813.9063 - val_loss: 4425236611072.0000 - val_mse: 4425236611072.0000\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 856.4786 - mse: 856.4786 - val_loss: 3865794838528.0000 - val_mse: 3865794838528.0000\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 930.6936 - mse: 930.6936 - val_loss: 4569838911488.0000 - val_mse: 4569838911488.0000\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 813.7601 - mse: 813.7601 - val_loss: 3794031607808.0000 - val_mse: 3794031607808.0000\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 806.0474 - mse: 806.0474 - val_loss: 3608654905344.0000 - val_mse: 3608654905344.0000\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 839.0430 - mse: 839.0430 - val_loss: 3942684033024.0000 - val_mse: 3942684033024.0000\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 798.8922 - mse: 798.8922 - val_loss: 4911166128128.0000 - val_mse: 4911166128128.0000\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 831.7455 - mse: 831.7455 - val_loss: 3774189142016.0000 - val_mse: 3774189142016.0000\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 849.2019 - mse: 849.2019 - val_loss: 3525564694528.0000 - val_mse: 3525564694528.0000\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 848.3457 - mse: 848.3457 - val_loss: 3481353060352.0000 - val_mse: 3481353060352.0000\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 905.1679 - mse: 905.1679 - val_loss: 4015907667968.0000 - val_mse: 4015907667968.0000\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 818.6669 - mse: 818.6669 - val_loss: 3764928380928.0000 - val_mse: 3764928380928.0000\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 831.8555 - mse: 831.8555 - val_loss: 5123672637440.0000 - val_mse: 5123672637440.0000\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 775.3849 - mse: 775.3849 - val_loss: 2881512538112.0000 - val_mse: 2881512538112.0000\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 892.1595 - mse: 892.1595 - val_loss: 4574072012800.0000 - val_mse: 4574072012800.0000\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 850.7047 - mse: 850.7047 - val_loss: 5201378410496.0000 - val_mse: 5201378410496.0000\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 830.1223 - mse: 830.1223 - val_loss: 3037781557248.0000 - val_mse: 3037781557248.0000\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 840.5955 - mse: 840.5955 - val_loss: 4120443617280.0000 - val_mse: 4120443617280.0000\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 827.5615 - mse: 827.5615 - val_loss: 3445425176576.0000 - val_mse: 3445425176576.0000\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 823.9971 - mse: 823.9971 - val_loss: 4847662792704.0000 - val_mse: 4847662792704.0000\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 768.0524 - mse: 768.0524 - val_loss: 2990039367680.0000 - val_mse: 2990039367680.0000\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 843.8263 - mse: 843.8263 - val_loss: 3737658064896.0000 - val_mse: 3737658064896.0000\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 820.5975 - mse: 820.5975 - val_loss: 3430658867200.0000 - val_mse: 3430658867200.0000\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 833.9883 - mse: 833.9883 - val_loss: 4063744491520.0000 - val_mse: 4063744491520.0000\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 809.3143 - mse: 809.3143 - val_loss: 4305379131392.0000 - val_mse: 4305379131392.0000\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 836.8401 - mse: 836.8401 - val_loss: 3572548239360.0000 - val_mse: 3572548239360.0000\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 902.3867 - mse: 902.3867 - val_loss: 3693308542976.0000 - val_mse: 3693308542976.0000\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 821.0093 - mse: 821.0093 - val_loss: 3862821076992.0000 - val_mse: 3862821076992.0000\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 836.4991 - mse: 836.4991 - val_loss: 3638254632960.0000 - val_mse: 3638254632960.0000\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 833.9128 - mse: 833.9128 - val_loss: 3461147262976.0000 - val_mse: 3461147262976.0000\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 850.1868 - mse: 850.1868 - val_loss: 3138995093504.0000 - val_mse: 3138995093504.0000\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 882.8708 - mse: 882.8708 - val_loss: 3625524133888.0000 - val_mse: 3625524133888.0000\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 812.0731 - mse: 812.0731 - val_loss: 3631962390528.0000 - val_mse: 3631962390528.0000\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 817.6785 - mse: 817.6785 - val_loss: 2929185783808.0000 - val_mse: 2929185783808.0000\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 853.2170 - mse: 853.2170 - val_loss: 2545317576704.0000 - val_mse: 2545317576704.0000\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 823.4785 - mse: 823.4785 - val_loss: 4278340288512.0000 - val_mse: 4278340288512.0000\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 823.8011 - mse: 823.8011 - val_loss: 2696451457024.0000 - val_mse: 2696451457024.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x147d6f58108>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1000, input_shape=(1,), activation='relu'))\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization()) # 두번째 레이어의 가중치를 모아주는 역할\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(1000))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/20 [>.............................] - ETA: 0s - loss: 6009034637312.0000 - mse: 6009034637312.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0051s vs `on_test_batch_end` time: 0.0120s). Check your callbacks.\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 2869579743232.0000 - mse: 2869579743232.0000\n",
      "acc :  2869579743232.0\n",
      "[[ 2451336.8 ]\n",
      " [-2537129.8 ]\n",
      " [  566805.2 ]\n",
      " [ 2229627.8 ]\n",
      " [-1317727.  ]\n",
      " [-1982855.6 ]\n",
      " [ 2673047.2 ]\n",
      " [ 1675353.9 ]\n",
      " [  843942.44]\n",
      " [ 1342789.  ]\n",
      " [  289667.8 ]\n",
      " [-1373154.  ]\n",
      " [-1761145.6 ]\n",
      " [-2426275.2 ]\n",
      " [ 1287362.4 ]\n",
      " [-2038282.8 ]\n",
      " [ 1897063.9 ]\n",
      " [  -98323.59]\n",
      " [ 1065652.2 ]\n",
      " [  -42896.25]]\n"
     ]
    }
   ],
   "source": [
    "loss, mse = model.evaluate(x_test, y_test, batch_size=1)\n",
    "print('acc : ', mse)\n",
    "\n",
    "y_predict = model.predict(x_test)\n",
    "print(y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  1693983.457613473\n"
     ]
    }
   ],
   "source": [
    "def RMSE(y_test, y_predict):\n",
    "    return np.sqrt(mean_squared_error(y_test, y_predict))\n",
    "print('RMSE : ', RMSE(y_test, y_predict)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 :  -3092594688.1924906\n"
     ]
    }
   ],
   "source": [
    "r2_y_predict = r2_score(y_test, y_predict)\n",
    "print('R2 : ', r2_y_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0f8330eff2168fad63f77d58953d6b7151d4acc41456747c4ca21d2a0343b66"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
