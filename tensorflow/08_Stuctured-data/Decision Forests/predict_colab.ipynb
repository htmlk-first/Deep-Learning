{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2022-12-14T12:06:48.291474Z",
     "iopub.status.busy": "2022-12-14T12:06:48.291007Z",
     "iopub.status.idle": "2022-12-14T12:06:48.295133Z",
     "shell.execute_reply": "2022-12-14T12:06:48.294519Z"
    },
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8yo62ffS5TF5"
   },
   "source": [
    "# Making predictions\n",
    "\n",
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/decision_forests/tutorials/predict_colab\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/decision-forests/blob/main/documentation/tutorials/predict_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/decision-forests/blob/main/documentation/tutorials/predict_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/decision-forests/documentation/tutorials/predict_colab.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zrCwCCxhiAL7"
   },
   "source": [
    "\n",
    "\n",
    "Welcome to the **Prediction Colab** for **TensorFlow Decision Forests** (**TF-DF**).\n",
    "In this colab, you will learn about different ways to generate predictions with a previously trained **TF-DF** model using the **Python API**.\n",
    "\n",
    "<i><b>Remark:</b> The Python API shown in this Colab is simple to use and well-suited for experimentation. However, other APIs, such as TensorFlow Serving and the C++ API are better suited for production systems as they are faster and more stable. The exhaustive list of all Serving APIs is available [here](https://ydf.readthedocs.io/en/latest/serving_apis.html).</i>\n",
    "\n",
    "In this colab, you will:\n",
    "\n",
    "1. Use the `model.predict()` function on a TensorFlow Dataset created with `pd_dataframe_to_tf_dataset`.\n",
    "1. Use the `model.predict()` function on a TensorFlow Dataset created manually.\n",
    "1. Use the `model.predict()` function on Numpy arrays.\n",
    "1. Make predictions with the CLI API.\n",
    "1. Benchmark the inference speed of a model with the CLI API.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1NlHfQyJ-e0"
   },
   "source": [
    "## Important remark\n",
    "\n",
    "The dataset used for predictions should have the **same feature names and types** as the dataset used for training. Failing to do so, will likely raise errors.\n",
    "\n",
    "For example, training a model with two features `f1` and `f2`, and trying to generate predictions on a dataset without `f2` will fail. Note that it is okay to set (some or all) feature values as \"missing\". Similarly, training a model where `f2` is a numerical feature (e.g., float32), and applying this model on a dataset where `f2` is a text (e.g., string) feature will fail. \n",
    "\n",
    "While abstracted by the Keras API, a model instantiated in Python (e.g., with\n",
    "`tfdf.keras.RandomForestModel()`) and a model loaded from disk (e.g., with\n",
    "`tf.keras.models.load_model()`) can behave differently. Notably, a Python\n",
    "instantiated model automatically applies necessary type conversions. For\n",
    "example, if a `float64` feature is fed to a model expecting a `float32` feature,\n",
    "this conversion is performed implicitly. However, such a conversion is not\n",
    "possible for models loaded from disk. It is therefore important that the\n",
    "training data and the inference data always have the exact same type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rzskapxq7gdo"
   },
   "source": [
    "## Setup\n",
    "\n",
    "First, we install TensorFlow Dececision Forests..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:06:48.299080Z",
     "iopub.status.busy": "2022-12-14T12:06:48.298525Z",
     "iopub.status.idle": "2022-12-14T12:06:50.683058Z",
     "shell.execute_reply": "2022-12-14T12:06:50.682216Z"
    },
    "id": "mZiInVYfffAb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_decision_forests\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached tensorflow_decision_forests-1.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.2 MB)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_decision_forests) (0.37.1)\r\n",
      "Requirement already satisfied: six in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_decision_forests) (1.16.0)\r\n",
      "Requirement already satisfied: absl-py in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_decision_forests) (1.3.0)\r\n",
      "Requirement already satisfied: tensorflow~=2.11.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_decision_forests) (2.11.0)\r\n",
      "Collecting wurlitzer\r\n",
      "  Using cached wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\r\n",
      "Requirement already satisfied: numpy in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_decision_forests) (1.24.0rc2)\r\n",
      "Requirement already satisfied: pandas in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow_decision_forests) (1.5.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (2.11.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.7.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.14.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.3.0)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.28.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (14.0.6)\r\n",
      "Requirement already satisfied: packaging in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (22.0)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.51.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (4.4.0)\r\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.0)\r\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (3.19.6)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (2.1.1)\r\n",
      "Requirement already satisfied: setuptools in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (65.6.3)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (1.6.3)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (0.2.0)\r\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (22.12.6)\r\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (2.11.0)\r\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorflow~=2.11.0->tensorflow_decision_forests) (2.11.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from pandas->tensorflow_decision_forests) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from pandas->tensorflow_decision_forests) (2022.6)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.4.6)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.2.2)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.28.1)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.15.0)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.4.1)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.6.1)\r\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.8.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.3.0rc1)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (5.2.0)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.3.1)\r\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (5.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2022.12.7)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (1.26.13)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.1.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (2.1.1)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zipp>=0.5 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.11.0)\r\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (0.5.0rc2)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /tmpfs/src/tf_docs_env/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow~=2.11.0->tensorflow_decision_forests) (3.2.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: wurlitzer, tensorflow_decision_forests\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed tensorflow_decision_forests-1.1.0 wurlitzer-3.0.3\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_decision_forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7PlfbnxYcPf"
   },
   "source": [
    "... , and import the libraries used in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:06:50.688744Z",
     "iopub.status.busy": "2022-12-14T12:06:50.688027Z",
     "iopub.status.idle": "2022-12-14T12:06:52.611568Z",
     "shell.execute_reply": "2022-12-14T12:06:52.610909Z"
    },
    "id": "RsCV2oAS7gC_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 12:06:51.603857: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-14 12:06:51.603946: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-14 12:06:51.603955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwcU4QF6AxiI"
   },
   "source": [
    "## `model.predict(...)` and `pd_dataframe_to_tf_dataset` function\n",
    "\n",
    "TensorFlow Decision Forests implements the [Keras](https://keras.io/) model API.\n",
    "As such, TF-DF models have a `predict` function to make predictions. This function  takes as input a [TensorFlow Dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) and outputs a prediction array.\n",
    "The simplest way to create a TensorFlow dataset is to use [Pandas](https://pandas.pydata.org/) and the the `tfdf.keras.pd_dataframe_to_tf_dataset(...)` function.\n",
    "\n",
    "The next example shows how to create a TensorFlow dataset using `pd_dataframe_to_tf_dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:06:52.616731Z",
     "iopub.status.busy": "2022-12-14T12:06:52.615212Z",
     "iopub.status.idle": "2022-12-14T12:06:52.627068Z",
     "shell.execute_reply": "2022-12-14T12:06:52.626513Z"
    },
    "id": "nto2KHQiCBbU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1 feature_2  label\n",
       "0          1         a      0\n",
       "1          2         b      1\n",
       "2          3         c      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_dataset = pd.DataFrame({\n",
    "    \"feature_1\": [1,2,3],\n",
    "    \"feature_2\": [\"a\", \"b\", \"c\"],\n",
    "    \"label\": [0, 1, 0],\n",
    "})\n",
    "\n",
    "pd_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:06:52.630281Z",
     "iopub.status.busy": "2022-12-14T12:06:52.629742Z",
     "iopub.status.idle": "2022-12-14T12:06:55.939885Z",
     "shell.execute_reply": "2022-12-14T12:06:55.939140Z"
    },
    "id": "G0VO-KajBmmd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: {'feature_1': <tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])>, 'feature_2': <tf.Tensor: shape=(3,), dtype=string, numpy=array([b'a', b'b', b'c'], dtype=object)>}\n",
      "label: tf.Tensor([0 1 0], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "tf_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(pd_dataset, label=\"label\")\n",
    "\n",
    "for features, label in tf_dataset:\n",
    "  print(\"Features:\",features)\n",
    "  print(\"label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bbekm7qCSSJ"
   },
   "source": [
    "<i>**Note:** \"pd_\" stands for \"pandas\". \"tf_\" stands for \"TensorFlow\".</i>\n",
    "\n",
    "A TensorFlow Dataset is a function that outputs a sequence of values. Those values can be simple arrays (called Tensors) or arrays organized into a structure (for example, arrays organized in a dictionary)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uom_NcOhNTyn"
   },
   "source": [
    "\n",
    "The following example shows the training and inference (using `predict`) on a toy dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:06:55.943562Z",
     "iopub.status.busy": "2022-12-14T12:06:55.943051Z",
     "iopub.status.idle": "2022-12-14T12:06:55.954511Z",
     "shell.execute_reply": "2022-12-14T12:06:55.953947Z"
    },
    "id": "BXrgkefvDg5T"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.683035</td>\n",
       "      <td>0.952359</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.486641</td>\n",
       "      <td>0.669202</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.685580</td>\n",
       "      <td>0.967570</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.233815</td>\n",
       "      <td>0.725952</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.250187</td>\n",
       "      <td>0.503956</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.676669</td>\n",
       "      <td>0.043817</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.564827</td>\n",
       "      <td>0.605345</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.996968</td>\n",
       "      <td>0.488901</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.987390</td>\n",
       "      <td>0.097840</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.692132</td>\n",
       "      <td>0.738431</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_1  feature_2  label\n",
       "0     0.683035   0.952359  False\n",
       "1     0.486641   0.669202  False\n",
       "2     0.685580   0.967570  False\n",
       "3     0.233815   0.725952  False\n",
       "4     0.250187   0.503956  False\n",
       "..         ...        ...    ...\n",
       "995   0.676669   0.043817   True\n",
       "996   0.564827   0.605345  False\n",
       "997   0.996968   0.488901   True\n",
       "998   0.987390   0.097840   True\n",
       "999   0.692132   0.738431  False\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a training dataset in Pandas\n",
    "pd_train_dataset = pd.DataFrame({\n",
    "    \"feature_1\": np.random.rand(1000),\n",
    "    \"feature_2\": np.random.rand(1000),\n",
    "})\n",
    "pd_train_dataset[\"label\"] = pd_train_dataset[\"feature_1\"] > pd_train_dataset[\"feature_2\"] \n",
    "\n",
    "pd_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:06:55.957619Z",
     "iopub.status.busy": "2022-12-14T12:06:55.957160Z",
     "iopub.status.idle": "2022-12-14T12:06:55.965255Z",
     "shell.execute_reply": "2022-12-14T12:06:55.964717Z"
    },
    "id": "dgRoofgPEIrk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.326467</td>\n",
       "      <td>0.689151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.807447</td>\n",
       "      <td>0.075198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.095011</td>\n",
       "      <td>0.947676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.851319</td>\n",
       "      <td>0.819100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488305</td>\n",
       "      <td>0.274047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.480803</td>\n",
       "      <td>0.238047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.633565</td>\n",
       "      <td>0.722966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.945247</td>\n",
       "      <td>0.128379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.267938</td>\n",
       "      <td>0.503427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.185848</td>\n",
       "      <td>0.901847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature_1  feature_2\n",
       "0     0.326467   0.689151\n",
       "1     0.807447   0.075198\n",
       "2     0.095011   0.947676\n",
       "3     0.851319   0.819100\n",
       "4     0.488305   0.274047\n",
       "..         ...        ...\n",
       "495   0.480803   0.238047\n",
       "496   0.633565   0.722966\n",
       "497   0.945247   0.128379\n",
       "498   0.267938   0.503427\n",
       "499   0.185848   0.901847\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a serving dataset with Pandas\n",
    "pd_serving_dataset = pd.DataFrame({\n",
    "    \"feature_1\": np.random.rand(500),\n",
    "    \"feature_2\": np.random.rand(500),\n",
    "})\n",
    "\n",
    "pd_serving_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uf85d4A4EKSO"
   },
   "source": [
    "Let's convert the Pandas dataframes into TensorFlow datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:06:55.968444Z",
     "iopub.status.busy": "2022-12-14T12:06:55.967923Z",
     "iopub.status.idle": "2022-12-14T12:06:55.985267Z",
     "shell.execute_reply": "2022-12-14T12:06:55.984707Z"
    },
    "id": "f1WzTT2mERSc"
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(pd_train_dataset, label=\"label\")\n",
    "tf_serving_dataset = tfdf.keras.pd_dataframe_to_tf_dataset(pd_serving_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oIN3uFAEZDT"
   },
   "source": [
    "We can now train a model on `tf_train_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:06:55.988503Z",
     "iopub.status.busy": "2022-12-14T12:06:55.988030Z",
     "iopub.status.idle": "2022-12-14T12:07:00.113654Z",
     "shell.execute_reply": "2022-12-14T12:07:00.113019Z"
    },
    "id": "DWO8wDrIEfXs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmpfs/src/tf_docs_env/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2022-12-14T12:06:58.981628493+00:00 kernel.cc:1175] Loading model from path /tmpfs/tmp/tmp0b3hukdi/model/ with prefix 0234a68d9d6c49ee\n",
      "[INFO 2022-12-14T12:06:59.017961685+00:00 abstract_model.cc:1306] Engine \"RandomForestOptPred\" built\n",
      "[INFO 2022-12-14T12:06:59.017993244+00:00 kernel.cc:1021] Use fast generic engine\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f76793294c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f76793294c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f76701969d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tfdf.keras.RandomForestModel(verbose=0)\n",
    "model.fit(tf_train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DrfobioEcXB"
   },
   "source": [
    "And then generate predictions on `tf_serving_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:00.117271Z",
     "iopub.status.busy": "2022-12-14T12:07:00.116639Z",
     "iopub.status.idle": "2022-12-14T12:07:00.161775Z",
     "shell.execute_reply": "2022-12-14T12:07:00.161145Z"
    },
    "id": "83w1-tpxEm2J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.99999917],\n",
       "       [0.        ],\n",
       "       [0.29666647],\n",
       "       [0.99999917],\n",
       "       [0.        ],\n",
       "       [0.99999917],\n",
       "       [0.99999917],\n",
       "       [0.99999917],\n",
       "       [0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 10 predictions.\n",
    "model.predict(tf_serving_dataset, verbose=0)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_D4Ft4o65XT"
   },
   "source": [
    "## `model.predict(...)` and manual TF datasets\n",
    "\n",
    "In the previous section, we showed how to create a TF dataset using the `pd_dataframe_to_tf_dataset` function. This option is simple but poorly suited for large datasets. Instead, TensorFlow offers [several options](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) to create a TensorFlow dataset.\n",
    "The next examples shows how to create a dataset using the `tf.data.Dataset.from_tensor_slices()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:00.165022Z",
     "iopub.status.busy": "2022-12-14T12:07:00.164502Z",
     "iopub.status.idle": "2022-12-14T12:07:00.176776Z",
     "shell.execute_reply": "2022-12-14T12:07:00.176107Z"
    },
    "id": "GLWaCAFf_IQi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: 1\n",
      "value: 2\n",
      "value: 3\n",
      "value: 4\n",
      "value: 5\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1,2,3,4,5])\n",
    "\n",
    "for value in dataset:\n",
    "  print(\"value:\", value.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxAdPFw7_u1X"
   },
   "source": [
    "TensorFlow models are trained with mini-batching: Instead of being fed one at a time, examples are grouped in \"batches\". For Neural Networks, the batch size impacts the quality of the model, and the optimal value needs to be determined by the user during training. For Decision Forests, the batch size has no impact on the model. However, for compatibility reasons, **TensorFlow Decision Forests expects the dataset to be batched**. Batching is done with the `batch()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:00.180172Z",
     "iopub.status.busy": "2022-12-14T12:07:00.179552Z",
     "iopub.status.idle": "2022-12-14T12:07:00.192915Z",
     "shell.execute_reply": "2022-12-14T12:07:00.192231Z"
    },
    "id": "S_mNd9fZ_s9-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "value: [1 2]\n",
      "value: [3 4]\n",
      "value: [5]\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1,2,3,4,5]).batch(2)\n",
    "\n",
    "for value in dataset:\n",
    "  print(\"value:\", value.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukbwYUaHFX4P"
   },
   "source": [
    "TensorFlow Decision Forests expects the dataset to be of one of two structures:\n",
    "\n",
    "- features, label\n",
    "- features, label, weights\n",
    "\n",
    "The features can be a single 2 dimensional array (where each column is a feature and each row is an example), or a dictionary of arrays.\n",
    "\n",
    "Following is an example of a dataset compatible with TensorFlow Decision Forests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:00.196045Z",
     "iopub.status.busy": "2022-12-14T12:07:00.195433Z",
     "iopub.status.idle": "2022-12-14T12:07:00.210095Z",
     "shell.execute_reply": "2022-12-14T12:07:00.209510Z"
    },
    "id": "ZRLOdY8GFsfi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "label: tf.Tensor([0 1], shape=(2,), dtype=int32)\n",
      "features: tf.Tensor([[5 6]], shape=(1, 2), dtype=int32)\n",
      "label: tf.Tensor([0], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# A dataset with a single 2d array.\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ([[1,2],[3,4],[5,6]], # Features\n",
    "    [0,1,0], # Label\n",
    "    )).batch(2)\n",
    "\n",
    "for features, label in tf_dataset:\n",
    "  print(\"features:\", features)\n",
    "  print(\"label:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:00.213158Z",
     "iopub.status.busy": "2022-12-14T12:07:00.212651Z",
     "iopub.status.idle": "2022-12-14T12:07:00.228226Z",
     "shell.execute_reply": "2022-12-14T12:07:00.227461Z"
    },
    "id": "sYyrKm5cGURD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: {'feature_1': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>, 'feature_2': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([4, 5], dtype=int32)>}\n",
      "label: tf.Tensor([0 1], shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: {'feature_1': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([3], dtype=int32)>, 'feature_2': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([6], dtype=int32)>}\n",
      "label: tf.Tensor([0], shape=(1,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# A dataset with a dictionary of features.\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\n",
    "    \"feature_1\": [1,2,3],\n",
    "    \"feature_2\": [4,5,6],\n",
    "    },\n",
    "    [0,1,0], # Label\n",
    "    )).batch(2)\n",
    "\n",
    "for features, label in tf_dataset:\n",
    "  print(\"features:\", features)\n",
    "  print(\"label:\", label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4udxrucRGiTj"
   },
   "source": [
    "Let's train a model with this second option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:00.231003Z",
     "iopub.status.busy": "2022-12-14T12:07:00.230783Z",
     "iopub.status.idle": "2022-12-14T12:07:00.516952Z",
     "shell.execute_reply": "2022-12-14T12:07:00.516278Z"
    },
    "id": "fievPXE9HMrU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2022-12-14T12:07:00.416575763+00:00 kernel.cc:1175] Loading model from path /tmpfs/tmp/tmpvzrrxxmw/model/ with prefix 0bc6f955d2d1456e\n",
      "[INFO 2022-12-14T12:07:00.440516186+00:00 kernel.cc:1021] Use fast generic engine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f75f016e220>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    ({\n",
    "    \"feature_1\": np.random.rand(100),\n",
    "    \"feature_2\": np.random.rand(100),\n",
    "    },\n",
    "    np.random.rand(100) >= 0.5, # Label\n",
    "    )).batch(2)\n",
    "\n",
    "model = tfdf.keras.RandomForestModel(verbose=0)\n",
    "model.fit(tf_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EniehXodHbg7"
   },
   "source": [
    "The `predict` function can be used directly on the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:00.520818Z",
     "iopub.status.busy": "2022-12-14T12:07:00.520190Z",
     "iopub.status.idle": "2022-12-14T12:07:00.656878Z",
     "shell.execute_reply": "2022-12-14T12:07:00.656178Z"
    },
    "id": "h3xL39glHfgT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43666634],\n",
       "       [0.58999956],\n",
       "       [0.42999968],\n",
       "       [0.73333275],\n",
       "       [0.75666606],\n",
       "       [0.20666654],\n",
       "       [0.67666614],\n",
       "       [0.66666615],\n",
       "       [0.82333267],\n",
       "       [0.3999997 ]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first 10 predictions.\n",
    "model.predict(tf_dataset, verbose=0)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhfzisp3HtHe"
   },
   "source": [
    "## `model.predict(...)` and `model.predict_on_batch()` on dictionaries\n",
    "\n",
    "In some cases, the `predict` function can be used with an array (or dictionaries of arrays) instead of TensorFlow Dataset.\n",
    "\n",
    "The following example uses the previously trained model with a dictionary of NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:00.660544Z",
     "iopub.status.busy": "2022-12-14T12:07:00.660013Z",
     "iopub.status.idle": "2022-12-14T12:07:00.757800Z",
     "shell.execute_reply": "2022-12-14T12:07:00.757176Z"
    },
    "id": "VsJvy9cbJiCp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6533328 ],\n",
       "       [0.5399996 ],\n",
       "       [0.2133332 ],\n",
       "       [0.22999986],\n",
       "       [0.16333325],\n",
       "       [0.18333323],\n",
       "       [0.3766664 ],\n",
       "       [0.5066663 ],\n",
       "       [0.20333321],\n",
       "       [0.8633326 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first 10 predictions.\n",
    "model.predict({\n",
    "    \"feature_1\": np.random.rand(100),\n",
    "    \"feature_2\": np.random.rand(100),\n",
    "    }, verbose=0)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYUenGgrJtW5"
   },
   "source": [
    "In the previous example, the arrays are automatically batched. Alternatively, the `predict_on_batch` function can be used to make sure that all the examples are run in the same batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:00.761294Z",
     "iopub.status.busy": "2022-12-14T12:07:00.760696Z",
     "iopub.status.idle": "2022-12-14T12:07:00.796375Z",
     "shell.execute_reply": "2022-12-14T12:07:00.795704Z"
    },
    "id": "TIn1tqEXKBh9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54666626],\n",
       "       [0.21666653],\n",
       "       [0.18333323],\n",
       "       [0.5299996 ],\n",
       "       [0.5499996 ],\n",
       "       [0.12666662],\n",
       "       [0.6299995 ],\n",
       "       [0.06000001],\n",
       "       [0.33999977],\n",
       "       [0.08999998]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first 10 predictions.\n",
    "model.predict_on_batch({\n",
    "    \"feature_1\": np.random.rand(100),\n",
    "    \"feature_2\": np.random.rand(100),\n",
    "    })[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sJ1rwOMVKP3N"
   },
   "source": [
    "\n",
    "**Note:** If `predict` does not work on raw data such as in the example above, try to use the `predict_on_batch` function or convert the raw data into a TensorFlow Dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3pGz9vYKmwr"
   },
   "source": [
    "## Inference with the YDF format\n",
    "\n",
    "This example shows how to run a TF-DF model trained with the CLI API ([one of the other Serving APIs](https://ydf.readthedocs.io/en/latest/serving_apis.html)). We will also use the Benchmark tool to measure the inference speed of the model.\n",
    "\n",
    "Let's start by training and saving a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:00.799563Z",
     "iopub.status.busy": "2022-12-14T12:07:00.799052Z",
     "iopub.status.idle": "2022-12-14T12:07:01.662055Z",
     "shell.execute_reply": "2022-12-14T12:07:01.661437Z"
    },
    "id": "n9fjcbx3LN4D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-14 12:07:00.950798: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1765] Subsample hyperparameter given but sampling method does not match.\n",
      "2022-12-14 12:07:00.950839: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1778] GOSS alpha hyperparameter given but GOSS is disabled.\n",
      "2022-12-14 12:07:00.950846: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1787] GOSS beta hyperparameter given but GOSS is disabled.\n",
      "2022-12-14 12:07:00.950852: W external/ydf/yggdrasil_decision_forests/learner/gradient_boosted_trees/gradient_boosted_trees.cc:1799] SelGB ratio hyperparameter given but SelGB is disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO 2022-12-14T12:07:01.160357659+00:00 kernel.cc:1175] Loading model from path /tmpfs/tmp/tmpo37712qo/model/ with prefix 391746915b7842cb\n",
      "[INFO 2022-12-14T12:07:01.164736847+00:00 kernel.cc:1021] Use fast generic engine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as call_get_leaves, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model = tfdf.keras.GradientBoostedTreesModel(verbose=0)\n",
    "model.fit(tfdf.keras.pd_dataframe_to_tf_dataset(pd_train_dataset, label=\"label\"))\n",
    "model.save(\"my_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_EZ3psELvVw"
   },
   "source": [
    "Let's also export the dataset to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:01.665221Z",
     "iopub.status.busy": "2022-12-14T12:07:01.664981Z",
     "iopub.status.idle": "2022-12-14T12:07:01.671658Z",
     "shell.execute_reply": "2022-12-14T12:07:01.671079Z"
    },
    "id": "1faR3HtpLxS3"
   },
   "outputs": [],
   "source": [
    "pd_serving_dataset.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X8_uk2CEL13p"
   },
   "source": [
    "Let's download and extract the [Yggdrasil Decision Forests](https://ydf.readthedocs.io/en/latest/index.html) CLI tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:01.674593Z",
     "iopub.status.busy": "2022-12-14T12:07:01.674367Z",
     "iopub.status.idle": "2022-12-14T12:07:04.092810Z",
     "shell.execute_reply": "2022-12-14T12:07:04.091987Z"
    },
    "id": "vVqrFqNuL_iL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-12-14 12:07:01--  https://github.com/google/yggdrasil-decision-forests/releases/download/1.0.0/cli_linux.zip\r\n",
      "Resolving github.com (github.com)... 140.82.114.3\r\n",
      "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 Found\r\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/360444739/bfcd0b9d-5cbc-42a8-be0a-02131875f9a6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221214%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221214T120701Z&X-Amz-Expires=300&X-Amz-Signature=94e7b8fd2c219cbe6305222b34f566360eb9fea8ea35e8303519f09b04744b93&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=360444739&response-content-disposition=attachment%3B%20filename%3Dcli_linux.zip&response-content-type=application%2Foctet-stream [following]\r\n",
      "--2022-12-14 12:07:01--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/360444739/bfcd0b9d-5cbc-42a8-be0a-02131875f9a6?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221214%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221214T120701Z&X-Amz-Expires=300&X-Amz-Signature=94e7b8fd2c219cbe6305222b34f566360eb9fea8ea35e8303519f09b04744b93&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=360444739&response-content-disposition=attachment%3B%20filename%3Dcli_linux.zip&response-content-type=application%2Foctet-stream\r\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.199.111.133, 185.199.110.133, 185.199.109.133, ...\r\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\r\n",
      "Length: 31516027 (30M) [application/octet-stream]\r\n",
      "Saving to: ‘cli_linux.zip’\r\n",
      "\r\n",
      "\r",
      "cli_linux.zip         0%[                    ]       0  --.-KB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "cli_linux.zip         2%[                    ] 727.40K  3.47MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "cli_linux.zip        13%[=>                  ]   4.01M  9.90MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "cli_linux.zip        53%[=========>          ]  16.01M  26.1MB/s               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "cli_linux.zip       100%[===================>]  30.06M  38.2MB/s    in 0.8s    \r\n",
      "\r\n",
      "2022-12-14 12:07:03 (38.2 MB/s) - ‘cli_linux.zip’ saved [31516027/31516027]\r\n",
      "\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  cli_linux.zip\r\n",
      "  inflating: README                  \r\n",
      "  inflating: cli.txt                 \r\n",
      "  inflating: train                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: show_model              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: show_dataspec           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: predict                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: infer_dataspec          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: evaluate                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: convert_dataset         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: benchmark_inference     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: edit_model              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: synthetic_dataset       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: grpc_worker_main        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  inflating: LICENSE                 \r\n",
      "  inflating: CHANGELOG.md            \r\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/google/yggdrasil-decision-forests/releases/download/1.0.0/cli_linux.zip\n",
    "!unzip cli_linux.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4lntgIjMw-m"
   },
   "source": [
    "Finally, let's make predictions:\n",
    "\n",
    "**Remarks:**\n",
    "\n",
    "\n",
    "- TensorFlow Decision Forests (TF-DF) is based on the [Yggdrasil Decision Forests](https://ydf.readthedocs.io/en/latest/index.html) (YDF) library, and  TF-DF model always contains a YDF model internally. When saving a TF-DF model to disk, the TF-DF model directory contains an `assets` sub-directory containing the YDF model. This YDF model can be used with all [YDF tools](https://ydf.readthedocs.io/en/latest/cli_commands.html). In the next example, we will use the `predict` and `benchmark_inference` tools. See the [model format documentation](https://ydf.readthedocs.io/en/latest/convert_model.html) for more details.\n",
    "- YDF tools assume that the type of the dataset is specified using a prefix, e.g. `csv:`. See the [YDF user manual](https://ydf.readthedocs.io/en/latest/cli_user_manual.html#dataset-path-and-format) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:04.096878Z",
     "iopub.status.busy": "2022-12-14T12:07:04.096163Z",
     "iopub.status.idle": "2022-12-14T12:07:04.266087Z",
     "shell.execute_reply": "2022-12-14T12:07:04.265344Z"
    },
    "id": "ckINgLzcMy_d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO abstract_model.cc:1296] Engine \"GradientBoostedTreesQuickScorerExtended\" built\r\n",
      "[INFO predict.cc:133] Run predictions with semi-fast engine\r\n"
     ]
    }
   ],
   "source": [
    "!./predict --model=my_model/assets --dataset=csv:dataset.csv --output=csv:predictions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOVWMGBCNiKp"
   },
   "source": [
    "We can now look at the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:04.269897Z",
     "iopub.status.busy": "2022-12-14T12:07:04.269292Z",
     "iopub.status.idle": "2022-12-14T12:07:04.282250Z",
     "shell.execute_reply": "2022-12-14T12:07:04.281723Z"
    },
    "id": "BQkAtPU_NkIF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.966779</td>\n",
       "      <td>0.033221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.031773</td>\n",
       "      <td>0.968227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.966779</td>\n",
       "      <td>0.033221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600073</td>\n",
       "      <td>0.399927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.030885</td>\n",
       "      <td>0.969115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.030885</td>\n",
       "      <td>0.969115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.948252</td>\n",
       "      <td>0.051748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.031773</td>\n",
       "      <td>0.968227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.966996</td>\n",
       "      <td>0.033004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.966779</td>\n",
       "      <td>0.033221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2\n",
       "0    0.966779  0.033221\n",
       "1    0.031773  0.968227\n",
       "2    0.966779  0.033221\n",
       "3    0.600073  0.399927\n",
       "4    0.030885  0.969115\n",
       "..        ...       ...\n",
       "495  0.030885  0.969115\n",
       "496  0.948252  0.051748\n",
       "497  0.031773  0.968227\n",
       "498  0.966996  0.033004\n",
       "499  0.966779  0.033221\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URt6PsCbNpR_"
   },
   "source": [
    "The speed of inference of a model can be measured with the [benchmark inference](https://ydf.readthedocs.io/en/latest/benchmark_inference.html) tool.\n",
    "\n",
    "**Note:** Prior to YDF version 1.1.0, the dataset used in the benchmark inference needs to have a `__LABEL` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:04.285335Z",
     "iopub.status.busy": "2022-12-14T12:07:04.284796Z",
     "iopub.status.idle": "2022-12-14T12:07:04.291369Z",
     "shell.execute_reply": "2022-12-14T12:07:04.290837Z"
    },
    "id": "NsT0lDmegpd1"
   },
   "outputs": [],
   "source": [
    "# Create the empty label column.\n",
    "pd_serving_dataset[\"__LABEL\"] = 0\n",
    "pd_serving_dataset.to_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T12:07:04.294431Z",
     "iopub.status.busy": "2022-12-14T12:07:04.293924Z",
     "iopub.status.idle": "2022-12-14T12:07:04.552098Z",
     "shell.execute_reply": "2022-12-14T12:07:04.551299Z"
    },
    "id": "yZPEvaHGNu_3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO benchmark_inference.cc:245] Loading model\r\n",
      "[INFO benchmark_inference.cc:248] The model is of type: GRADIENT_BOOSTED_TREES\r\n",
      "[INFO benchmark_inference.cc:250] Loading dataset\r\n",
      "[INFO benchmark_inference.cc:259] Found 3 compatible fast engines.\r\n",
      "[INFO benchmark_inference.cc:262] Running GradientBoostedTreesGeneric\r\n",
      "[INFO decision_forest.cc:639] Model loaded with 27 root(s), 1471 node(s), and 2 input feature(s).\r\n",
      "[INFO benchmark_inference.cc:262] Running GradientBoostedTreesQuickScorerExtended\r\n",
      "[INFO benchmark_inference.cc:262] Running GradientBoostedTreesOptPred\r\n",
      "[INFO decision_forest.cc:639] Model loaded with 27 root(s), 1471 node(s), and 2 input feature(s).\r\n",
      "[INFO benchmark_inference.cc:268] Running the slow generic engine\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size : 100  num_runs : 50\r\n",
      "time/example(us)  time/batch(us)  method\r\n",
      "----------------------------------------\r\n",
      "         0.22425          22.425  GradientBoostedTreesOptPred [virtual interface]\r\n",
      "          0.2465           24.65  GradientBoostedTreesQuickScorerExtended [virtual interface]\r\n",
      "          0.6875           68.75  GradientBoostedTreesGeneric [virtual interface]\r\n",
      "           1.825           182.5  Generic slow engine\r\n",
      "----------------------------------------\r\n"
     ]
    }
   ],
   "source": [
    "!./benchmark_inference \\\n",
    "  --model=my_model/assets \\\n",
    "  --dataset=csv:dataset.csv \\\n",
    "  --batch_size=100 \\\n",
    "  --warmup_runs=10 \\\n",
    "  --num_runs=50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neE7VAB6grdg"
   },
   "source": [
    "In this benchmark, we see the inference speed for different inference engines. For example, \"time/example(us) = 0.6315\" (can change in different runs) indicates that the inference of one example takes 0.63 micro-seconds. That is, the model can be run ~1.6 millions of times per seconds.\n",
    "\n",
    "**Note:** TF-DF and the other API always automatically select the fastest inference engine available."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "predict_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
